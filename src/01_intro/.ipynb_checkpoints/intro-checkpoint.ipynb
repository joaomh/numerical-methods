{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roundoff and Truncation Errors\n",
    "\n",
    "Sometimes as scientsits and engineers we have to deal with errors in ours models,\n",
    "especially when we are solving problems using computational methods.\n",
    "Computation errors, also called numerical errors, include both truncation errors and roundoff errors. \n",
    "\n",
    "## Round-off Error\n",
    "A roundoff error, also called rounding error, is the difference between the result produced by a given algorithm using exact arithmetic and the result produced by the same algorithm using finite-precision, rounded arithmetic. Rounding errors are due to inexactness in the representation of real numbers and the arithmetic operations done with them. This is a form of quantization error. When using approximation equations or algorithms, especially when using finitely many digits to represent real numbers (which in theory have infinitely many digits), one of the goals of numerical analysis is to estimate computation errors. \n",
    "\n",
    "## Truncation error\n",
    "In numerical analysis and scientific computing, truncation error is the error made by truncating an infinite sum and approximating it by a finite sum.\n",
    "\n",
    "For instance, if we approximate the sine function by the first two non-zero term of its Taylor series, as in \n",
    "\n",
    "$$ sin = x - x^3\\frac{1}{6}$$\n",
    "\n",
    "for small $x$, the resulting error is a truncation error. It is present even with infinite-precision arithmetic, because it is caused by truncation of the infinite Taylor series to form the algorithm.\n",
    "\n",
    "## Representation error\n",
    "Here are some examples of representation error in decimal representations:\n",
    "\n",
    "|Notation |\tRepresentation | Approximation |Error|\n",
    "| --- | --- | --- |---|\n",
    "|1/7| $0.\\overline{142857}$ \t|0.142857 |$0.000000\\overline{142857}$|\n",
    "|$e$|2.71828182845904523536...|2.718281828459045|0.00000000000000023536... |\n",
    "|$\\sqrt{2}$|1.41421356237309504880...| 1.41421|0.00000356237309504880...| \n",
    "|$\\pi$ \t|3.14159265358979323846... |\t3.141592653589793 |\t0.00000000000000023846... |\n",
    "\n",
    "## Floating-point number system\n",
    "Compared with the fixed-point number system, the floating-point number system is more efficient in representing real numbers so it is widely used in modern computers. While the real numbers  $\\mathbb {R}$  are infinite and continuous, a floating-point number system $F$ is finite and discrete. Thus, representation error, which leads to roundoff error, occurs under the floating-point number system. \n",
    "\n",
    "### Notation of floating-point number system\n",
    "A floating-point number system $F$ is characterized by $4$ integers:\n",
    "\n",
    "$\\beta$ : base or radix\n",
    "\n",
    "$p$: precision\n",
    "\n",
    "$[L,U]$: exponent range, where $L$ is the lower bound and $U$ is the upper bound.\n",
    "\n",
    "Any $x$ $∈$ $F$ $ x\\in F$ has the following form:\n",
    "\n",
    "$ x = \\pm(\\underbrace{d_0.d_1d_2...d_{p-1}}_{mantissa})_{\\beta}\\times \\beta^{\\overbrace{E}^{exponent}} = \\pm d_0\\times \\beta^E +d_1\\times\\beta^{E-1}+...+d_{p-1}\\times\\beta^{E-(p-1)} $\n",
    "\n",
    "Where $d_i$ is an integer such that $0\\leq d_{i}\\leq \\beta -1$ for $i = 0 , 1 , … , p − 1 ${\\displaystyle i=0,1,\\ldots ,p-1} {\\displaystyle i=0,1,\\ldots ,p-1}, and $E$ is an integer such that $ L\\leq E\\leq U$.\n",
    "\n",
    "### IEEE standard\n",
    "In the IEEE standard the base is binary, i.e. $\\beta = 2$, and normalization is used. The IEEE standard stores the sign, exponent, and mantissa in separate fields of a floating point word, each of which has a fixed width (number of bits). The two most commonly used levels of precision for floating-point numbers are single precision and double precision. \n",
    "\n",
    "\n",
    "|Precision| \tSign (bits) |\tExponent (bits) |\tMantissa (bits)|\n",
    "| --- | --- | --- |---|\n",
    "|Single |\t1 |\t8 \t|23|\n",
    "|Double| \t1 |\t11 |\t52 |\n",
    "\n",
    "## Machine epsilon\n",
    "Machine epsilon can be used to measure the level of roundoff error in the floating-point number system. Here are two different definitions.\n",
    "\n",
    "The machine epsilon, denoted $ \\epsilon _{mach} $, is the maximum possible absolute relative error in representing a nonzero real number $x$ in a floating-point number system.\n",
    "\n",
    "$$ \\epsilon _{mach}=max\\frac{|x-fl(x)|}{|x|} $$\n",
    "\n",
    "\n",
    "## Unstable algorithms\n",
    "An algorithm or numerical process is called stable if small changes in the input only produce small changes in the output and it is called unstable if large changes in the output are produced. A sequence of calculations normally occur when running some algorithm. The amount of error in the result depends on the stability of the algorithm. Roundoff error will be magnified by unstable algorithms. \n",
    "\n",
    "## References\n",
    "\n",
    "- [Round-off error](https://en.wikipedia.org/wiki/Round-off_error)\n",
    "- [Half-precision floating-point format](https://en.wikipedia.org/wiki/Half-precision_floating-point_format)\n",
    "- [Octuple-precision floating-point format](https://en.wikipedia.org/wiki/Octuple-precision_floating-point_format)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
